

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 3, 'k': 500, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 500, 'n_init': 5}
 K-means random forest with precision: 0.284789644013 
predicted labels: [ 0  0  0 58 59 26  2  2  2  3  2  3  2 58 58  5  5 55 26 26 33  2  2  2  8
  2 58  2 19  2 10 10 10 11 26 26 26  0 26 33 42 42  2  2  2 42 26 26 58 19
 64 26 26 26  2  2 58 19 19 19 26 26 26  2  2  2 22 22 22  1  1 23 24 58 26
 25 26 26 26 26 26 26  2 58 28 28 28 29 64  2  2  2  2  2 26 26 58 32 58 26
 33 58  2  2 58 35 19 26  0  0 19 41 37 41 38 38 38 64 58 19 58 58 26 41 41
 58 42 42 42 43 19  0 58  2  0  2 55  2 26 26 26 26 42 42 58 48 58 49  2 58
  2 58  2 51 51 58 52 52 52  2  2 19 54  2 54 55  2  2 56  2  2 57 26 26 58
 58 58 26  2 19  2  2  2 59 61 59 62 58  2 63 63 58 64 64 64 65 65 65 66 58
 63  2  0 64 68  2  2 58 19  2  2  2  2 71 26 26 19 19  0 73 73 73 74 26 26
  2  2 19 58  2 58 77 58 58 78  2  2 79 26 26 80 80 80  2  2 19  2  2 19 83
 58 58 67 64  2  2  2 26  2  2  2  2 87  2  2  2  2  0  0 58  0 90 90  2 58
 26 59 58  2  1  2 26  2  2 94 95  0 58  2  0 58  2 59 58  0  2 58 19 58  2
  2  2  2 41 58 58  2  2  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 5, 'k': 500, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 500, 'n_init': 5}
 K-means random forest with precision: 0.258899676375 
predicted labels: [ 0  0  0 58  2  2  2  2  2  2 26  2  2 58 58  5  5 55 26 26 26  2  2  2  8
  2 58  2  2  2 10 10 58 11 26 26 19 55 58 33 26 42  2  2  2 26 26 26 58 19
 58 26 33 26  2 64  2 19 19 19 42 42 42  2  2  2 22 22 22  1  1 23 26 64 58
 25 33 33 26 26 26  2  2  2 28 28 28 29 64 51  2  2  2 58  2  2 58 32 58 33
 33 58  2  2 58 35 19 59  0  0 19  0 37  0 38 38 38 64 58  2  2  2 26 41  2
 19 42 42 42 43 19  0 58  2  0  2 55  2 26 26 26 26 26 26 19 48 19 49  2 58
  2  2  2 51 51 58 52 52 52  2  2  2  2  2 19 55 55  2 56  2  0 57 26 26 58
 58 58 59 58 19  2  2  2  2 61  2 62  2  2 63 63 58 64 64 64 65 65 65 66 63
 58  2  0  2 68  2  2 58  2  2  2  2  2 26 26 26 19 19  0 73 73  2 74 26 26
 58 58 19  2 59 58 77 64  2 78  2  2 79 26 26 80 80 80  2  2 58  2  2 19 83
 26 58 67  2 58  2  2 58  2  2  2  2 87  2  0  2  2  0  2 58 58  2  2 58 58
 26 58  2  2  1  2 26  2  2 94 95  2 58 58 59 58  0 59 58 58  2 58 19 58  2
 19  2 26  2 19  2  2  2  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 7, 'k': 500, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 500, 'n_init': 5}
 K-means random forest with precision: 0.236245954693 
predicted labels: [ 0  0  0 58 19 26 58  2  2  2  0  3 59 94 94  5  5 55 26 26 26  0  2  2  8
  2 58 26 58  2 10 10 58 11 26 26 19  0 26 33 26 42  2  2  2 42 26 26 58  2
 64 26 33 26  2  2  2 19 19 58 26 26 33  0  2 58 22 22 22  1  1 42 26 64 58
 25 33 33 26 26 26  2  0  2 28 28 28 29 64  2  2 55  2 58  2 59  2 32  2 42
 33 14 55 58 58 35  0 26  0  0  2  0 37  0 38 10 10 64 64  2  2  2  0 41  2
 58 42 42 42 43 58  0 58  2  0 55 55  2 26 26 26 26 42 42 58 48 58 49 58 58
  2  2  2 51 51 58 52 52 52  2 58  2 55  2 19 55 55  2 56  2  0 57 33 26 58
 19 58 26  2 19  2  2  2  2 61  2 62  2  2 63 63 58 64 64 64 65 65 65 66 63
 94 55  0  2 68  2  2  2  2  2  2  2 19 26 26 26 19 19 64 73 73  0 74 33 26
 58 58  2 58  2  2 77 64 26 78  3  2 79 26 26 80 80 80 59 59 58  0  0 55 83
 26 58 55 58  2 26  2 58  2 55  2  2 87  2  0  2  3  0  0 19 58  0  0 58 58
 26 59 55  2  1  2 26  2  2 94 95  3 58 55 59 58  2 19 58 19 64 26  0 58  2
 58  2  3  2 19 58  2 58  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 10, 'k': 500, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 500, 'n_init': 5}
 K-means random forest with precision: 0.229773462783 
predicted labels: [26  0  0 19 19 26 58  2  2  2 26  0  2  2  2  5  5 55 26 26 26  0  2  2  8
  2 58  0 51  2 10 10 59 11 26 19  0 55 26 33 33 33 59  2  2 42 26 26 10  2
 19  0 33 26  2  0  0 19 58 58 11 11 33 26  2 19 22 22 22  1  1 26 26 64 26
 25 33 33 26 26 26  2  2 59 28 28 28 29 64 58  2 55  2 58  2  0  2 32  2  2
 33 55  2 58 58 35  0 59  0  0 26  2 37  2 38 10 10 64 26  0  2  2  0 41  2
 58 42 42 42 43  2  2 26 59  2 55  2  0 26 26 26 33 42 42 58 48 58 49  2 58
  2 58  2 51 51 58 52 52 52  2  2  2  2  2 58 55 55 55 56  2  0 57 26 26 58
 58 58 26 58 58  2  0 19 59 61 59 62  2 55 63 63 58 64 11 64 65 65 65 66  2
 63 55  0  2 68  2  2 26  2  2  2  2 19 52 52 26 26 58 26 73 73  2 74 33 26
 58 58 58 58  2  2 77 26 26 78  0 55 79 52 33 80 80 80 59 59 58  2  2 55 83
 52 19 64 64  2 26  2 26  2 55  2 26 87 26  0  2  3  0 26 58 58 58 58 19 58
 19 19 55 59  1  2 52  2  2 94 95  0 58 58 26 26  2 26 26 58 64 26  2 26  2
 26  2 59  2 19  2  2 58  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 3, 'k': 1000, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 1000, 'n_init': 5}
 K-means random forest with precision: 0.252427184466 
predicted labels: [ 0  0  0 58 19 26  2 19  2  3  2 59 19 58 58  5  5 55 26 26 26  2 58  2  8
  2 58  2 19  2 10 10  2 11 26 26 26  0 26 26 26 42  2  2  2 26 26 26 58 19
 58 26 33 26  2  2  2 19 19 19 26 26 26  2  2  2 22 22 22  1  1 23 26 58 26
 25 26 26 26 26 26 26  2  2 28 28 28 29 58  2 59  2  2  2 26 26 58 32 58 26
 33 58  2  2 58 35 19  0  0  0  2 19 37 19 38  2  2 64  2  2 58 58 26 41  2
 26 42 42 42 43  2  2 19  2  0  2  2  2 26 26 26 26 42 42 58 48 58 49 19 58
  2 58  2 51 51 58 52 52 52  2  2  2 19  2 54 55 55  2 56  2 19 57 26 26 58
 58 58 26  2 59  2  2  2  2 61  2 62  2  2 63 63 58 64 64 64 65 65 65 66 58
 58  2  0 58 68  2  2 58 58  2  2  2  2 71 26 26 19 19  0 73 73  2 74 26 26
  2  2 58  2  2 58 77 64 58 78 58  2 79 26 26 80 80 80  2  2 26  2  2 19 83
 58 58 55 59  2  2 58 26  2  2  2  2 87  2  2  2  2  0  0 19 58 58 58  2 58
 26  2  2 55  2  2 26  2  2  2 95  2  2  2 51 58  2 26  2  0  2  2 19 58 58
 58  2  2  2 19 58  2 58  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 5, 'k': 1000, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 1000, 'n_init': 5}
 K-means random forest with precision: 0.245954692557 
predicted labels: [ 0  0  0 58 58  2 58  2  2  2  2  2 19 58 58  5  5  2 26 26 26  2  2  2  8
  2 58  2  2  2 10 10 58 11 26 26 58  0 26 26 42 26  2  2  2 26 26 26 19 19
 58 26 26 26  2  2  2 19 19 19 26 26 26  2  2  2 22 22 22  1  1 23 24 58 58
 25 26 26 26 26 26 58  2  2 28 28 28 29 64 58 58  2  2 58  2 58  2 32  2 26
 33 58 19  2 58 35 19 19  2  2  2 55 37 55 38 26 26 64 58 64  2  2 26 41  2
 26 42 42 42 43 58  2 26  2  2 58  2  2 26 26 26 26 26 26 19 48 19 49 49 58
  2  2  2 51 51 58 52 52 52  2  2 58  2  2 19 55  2  2 56  2 19 57 26 26 58
 58 58  2  2 19  2  2  2  2 61  2 62  2 58 63 63 58 64 64 64 65 65 65 66 63
 63  2  2 64 68  2  2 58 58  2  2  2  2 71 26 26 19 19  0 73 73  2 74 26 26
 58 58 58  2  2 58 77 64 58 78  2  2 79 26 26 80 80 80 58 58 58  2  2  2 83
 26 58 64 64  2  2  2  2  2  2  0  2 87  2  2  2  2  0  2 58 58  2  2 58 58
 26 58  2  2  1  2 26  2  2  2 95 19 58  2 59 58  2 26 19 58  2  2 19 58 58
 58  2 26  2 19 58  2  2  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 7, 'k': 1000, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 1000, 'n_init': 5}
 K-means random forest with precision: 0.252427184466 
predicted labels: [ 0  0  0 58  2 26 58  2  2  2  2 55  2  2  2  5  5  2 26 26 26  0  2 58  8
  2 58 26 58  2 10 10 58 11 26 26 19 58 26 33 26 33  2  2  2 26 26 26 58 19
 58 26 33 26  2 55  2 19 19 19 26 26 26 58  2 58 22 22 22 23 23 23 26 64 58
 25 26 26 26 26 26  2  2  2 28 28 28 29 58 19  2 55  2  2  2  2 58 32 58 26
 33 58 58  2 58 35 58 59  2  2  2  0 37  0 38 26 26 64 58  2  2  2  0 41  2
 58 42 42 42 43 58  0 26  2  0 55 55  2 26 26 26 26 26 26 58 48 58 49  2 58
  2  2  2 51 51 58 52 52 52  2  2  2  2  2 58 55 55  2 56  2 19 57 33 26 58
 58 58 26  2 19  2  2  2  2 61  2 62  2 58 63 63 58 64 64 64 65 65 65 66  2
  2 67  0 58 68  2  2  2  2  2  2  2  2 26 26 26 26 19 58 73 73  2 74 33 26
 58 58  2  2  2  2 77 64  0 78  2  2 79 26 26 80 80 80  2  2 58  2  2 19 83
 26 58 55 58  2 26  2 58  2 55  2  2 87  2  2  2  2  0  2 19 58  2  2 58 58
 58  2  2  2  1  2 26  2  2 94 95  0 58 58 59 58 26 19 58  2  2 26 19 58  2
 58  2 26  2 19 58  2 58  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]

--------

Running experiment: run_kmeans_ngram with parameters: {'n_estimators': 10000, 'n': 10, 'k': 1000, 'n_test': 3, 'dataset': 'long_comments'}
kmeans arguments: {'max_iter': 100, 'n_jobs': 1, 'verbose': True, 'n_clusters': 1000, 'n_init': 5}
 K-means random forest with precision: 0.229773462783 
predicted labels: [ 0 26  0 58  2 26 58  2  2  2  2  3  2  2  2  5  5  2 26 26 26  0  2  2  8
  2 58 26  2  2 10 10 19 11 26 26 19  0 26 33 42 33  2  2  2 26 26 26 58 58
 58 26 33 26  2  2  2 19  2 58 26 26 52  0  2 58 22 22 22  1  1 23 26 26 26
 25 33 33 26 26 26  2 59  2 28 28 28 29 64 58  2  2  2  2  2 58  2 32  2  2
 33 58 58 58 58 35  0 59  0  0 58  2 37  2 38 10 10 64 26 58  2  2  0 41  2
 58 42 42 42 43 19  2 26 59  2  2  2  2 26 26 26 26 26 26 58 48 58 49  2 58
  2 58  2 51 51 58 52 52 26  2  2  2  2  2  2 55 55  2 56  2 19 57 26 26  2
 58 58 26 58  2  2  2 19  2 61  2 62  2  2 63 63 58 64 64 64 65 65 65 66 19
  2 55  0  2 68  2  2 26  2  2  2  2  2 26 26 26 59 19 26 73 73  0 74 33 26
 58 58 19 58  2  2 77 19  0 78 55  2 79 26 26 80 80 80  2  2 58  0  2 55 83
 26 19 64 58  2 26  2 58  2  2  2 26 87 26  0  2  3  0  0 58 58  2  2 19 58
 19 26 55  0  1  2 26  2  2 94 95  0 58 58 58 58  2 26 26 58 64 26  2 58  2
 19  2  0  2 19 58  2 58  2] 
actual labels: [  0   0   0   1   1   1   2   2   2   3   3   3   4   4   4   5   5   5
   6   6   6   7   7   7   8   8   8   9   9   9  10  10  10  11  11  11
  12  12  12  13  13  13  14  14  14  15  15  15  16  16  16  17  17  17
  18  18  18  19  19  19  20  20  20  21  21  21  22  22  22  23  23  23
  24  24  24  25  25  25  26  26  26  27  27  27  28  28  28  29  29  29
  30  30  30  31  31  31  32  32  32  33  33  33  34  34  34  35  35  35
  36  36  36  37  37  37  38  38  38  39  39  39  40  40  40  41  41  41
  42  42  42  43  43  43  44  44  44  45  45  45  46  46  46  47  47  47
  48  48  48  49  49  49  50  50  50  51  51  51  52  52  52  53  53  53
  54  54  54  55  55  55  56  56  56  57  57  57  58  58  58  59  59  59
  60  60  60  61  61  61  62  62  62  63  63  63  64  64  64  65  65  65
  66  66  66  67  67  67  68  68  68  69  69  69  70  70  70  71  71  71
  72  72  72  73  73  73  74  74  74  75  75  75  76  76  76  77  77  77
  78  78  78  79  79  79  80  80  80  81  81  81  82  82  82  83  83  83
  84  84  84  85  85  85  86  86  86  87  87  87  88  88  88  89  89  89
  90  90  90  91  91  91  92  92  92  93  93  93  94  94  94  95  95  95
  96  96  96  97  97  97  98  98  98  99  99  99 100 100 100 101 101 101
 102 102 102]